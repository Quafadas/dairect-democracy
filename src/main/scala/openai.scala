package io.github.quafadas.dairect

import smithy4s.*
import smithy4s.Document.*
import smithy4s.json.Json
import smithy4s.schema.*
import smithy4s.schema.Primitive.*

import smithy4s.deriving.{given, *}
import smithy4s.deriving.aliases.{*, given}
import cats.effect.IO
import scala.annotation.experimental
import smithy.api.*
import smithy.api.NonEmptyString.asBijection
import smithy4s.http4s.SimpleRestJsonBuilder
import org.http4s.syntax.all.uri
import org.http4s.client.Client
import org.http4s.headers.Authorization
import org.http4s.AuthScheme
import org.http4s.Headers
import org.http4s.Credentials
import smithy.api.Error.CLIENT
import cats.effect.IOApp
import cats.effect.ExitCode
import ciris.*
import cats.effect.kernel.Resource
import org.http4s.client.middleware.Logger
import javax.xml.namespace.QName

import Agent.ChatCompletionResponseMessageFunctionCall
import Agent.FunctionCall
import smithy4s.deriving.internals.Meta
import cats.effect.std.Random
import org.http4s.Uri
import io.github.quafadas.dairect.Agent.AiMessage.tool
import cats.syntax.traverse.toTraverseOps
import cats.instances.list.*
import smithy4s.kinds.FunctorAlgebra
import cats.collections.syntax.all

@experimental
object Agent:

  enum ContinueFold:
    case Stop
    case Continue
  end ContinueFold

  /** @param model
    *   \- An implementation of the ChatGpt service. There is not a "single" one of these, as it is anticipated that
    *   people may wish to configure different middle (logging et al) for individual agents.
    * @param seedMessages
    *   \- The messages that will seed the conversation with this agent.
    * @param modelParams
    *   \- Params to call chatGPT with.
    * @return
    */
  def startAgent[Alg[_[_, _, _, _, _]]](
      model: ChatGpt,
      seedMessages: List[AiMessage],
      modelParams: ChatGptConfig,
      toolkit: FunctorAlgebra[Alg, IO]
  )(implicit S: Service[Alg]) =
    val functions = ioToolGen.toJsonSchema(toolkit)
    val functionDispatcher = ioToolGen.openAiSmithyFunctionDispatch(toolkit)
    fs2.Stream
      .unfoldEval[IO, (ContinueFold, List[AiMessage]), List[AiMessage]]((ContinueFold.Continue, seedMessages)) { (continue, allMessages) =>

        continue match
          case ContinueFold.Stop => IO.pure(None)
          case ContinueFold.Continue =>
            model
              .chat(
                model = modelParams.model,
                temperature = modelParams.temperature,
                messages = allMessages,
                tools = Some(functions)
              )
              .flatMap { response =>
                // println(response)
                val botChoices = response.choices.head
                val responseMsg = botChoices.message
                botChoices.finish_reason match
                  case None =>
                    IO.raiseError(
                      new Exception("No finish reason provided. Bot should always provide a finish reason")
                    )
                  case Some(value) =>
                    value match
                      case "tool_calls" =>
                        val fctCalls = botChoices.message.tool_calls.getOrElse(List.empty)
                        val newMessages = fctCalls
                          .traverse(fct =>
                            functionDispatcher.apply(fct.function).map { result =>
                              AiMessage.tool(
                                tool_call_id = fct.id,
                                content = Json.writeDocumentAsPrettyString(result)
                              )
                            }
                          )
                          .map { msgs =>                        
                            allMessages ++ botChoices.toMessage ++ msgs
                          }
                        newMessages.map(msgs => Some((msgs, (ContinueFold.Continue, msgs))))

                      case "stop" =>                        
                          val finalMessages = allMessages ++ botChoices.toMessage
                          IO.pure(Some((finalMessages, (ContinueFold.Stop, finalMessages))))
                      case _ =>
                        IO.println("Bot finished with unknown finish reason") >>
                          IO.println(response) >>
                          IO.raiseError(new Exception("Bot finished with unknown finish reason"))

                end match
              }

          }
          .compile
          .lastOrError
        
  end startAgent

  case class ChatGptConfig(
      model: String,
      temperature: Option[Double]
  ) derives Schema

  /** The name and arguments of a function that should be called, as generated by the model.
    * @param name
    *   The name of the function to call.
    * @param arguments
    *   The arguments to call the function with, as generated by the model in JSON format. Note that the model does not
    *   always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the
    *   arguments in your code before calling your function.
    */
  case class ChatCompletionResponseMessageFunctionCall(name: Option[String] = None, arguments: Option[String] = None)
      derives Schema

  case class ChatCompletionResponseMessage(
      role: String,
      content: Option[String] = None,
      function_call: Option[ChatCompletionResponseMessageFunctionCall] = None
  ) derives Schema

  case class ChatResponse(
      id: String,
      created: Int,
      model: String,
      choices: List[AiChoice],
      usage: AiTokenUsage
  ) derives Schema

  case class AiTokenUsage(
      completion_tokens: Int,
      prompt_tokens: Int,
      total_tokens: Int
  ) derives Schema

  case class AiMessage(
      role: String,
      content: Option[String] = None,
      tool_calls: Option[List[ToolCall]] = None,
      tool_call_id: Option[String] = None
  ) derives Schema

  object AiMessage:
    // Sent by us to the AI
    def user(content: String): AiMessage =
      AiMessage("user", Some(content))

    // Seeds the conversation with the AI
    def system(content: String): AiMessage = AiMessage("system", Some(content))

    // A message from the AI to us
    def assistant(content: Option[String], tool_calls: List[ToolCall]): AiMessage =
      (content, tool_calls) match
        case (None, x :: xs) =>
          AiMessage("assistant", None, Some(tool_calls))
        case (Some(content), Nil) =>
          AiMessage("assistant", Some(content), Some(tool_calls))
        case _ => throw new Exception("Assistant message must have only one of content OR tool calls")

    // A message from a tool to the AI
    def tool(content: String, tool_call_id: String): AiMessage =
      AiMessage("tool", Some(content), None, Some(tool_call_id))

  end AiMessage

  // https: // platform.openai.com/docs/api-reference/chat
  type BaseAiMessage = SystemMessage | UserMessage | BotMessage | ToolMessage

  case class SystemMessage(
      content: String,
      role: String = "system",
      name: Option[String] = None
  ) derives Schema

  case class UserMessage(
      role: String = "user",
      content: String,
      name: Option[String] = None
  ) derives Schema

  case class BotMessage(
      role: String = "assistant",
      content: Option[String],
      tool_calls: String
  ) derives Schema

  case class ToolMessage(
      role: String = "tool",
      content: String,
      tool_call_id: String
  ) derives Schema

  case class AiChoice(message: AiAnswer, finish_reason: Option[String]) derives Schema

  case class AiAnswer(role: String, content: Option[String], tool_calls: Option[List[ToolCall]]) derives Schema

  // case class AiResponseFormat(`type`: String) derives Schema

  case class ToolCall(id: String, `type`: String = "function", function: FunctionCall) derives Schema

  case class FunctionCall(name: String, description: Option[String], arguments: Option[String]) derives Schema

  @experimental
  @simpleRestJson
  trait ChatGpt derives API:
    /**
      * https://platform.openai.com/docs/api-reference/chat
      */  
    @hints(Http(NonEmptyString("POST"), NonEmptyString("/v1/chat/completions"), 200))
    def chat(
        model: String,
        messages: List[AiMessage],        
        temperature: Option[Double],        
        tools: Option[Document] = None,
        responseFormat: Option[AiResponseFormat] = None,
    ): IO[ChatResponse] = ???
  end ChatGpt

  object ChatGpt:
    def apply(client: Client[IO], baseUrl: Uri): Resource[IO, ChatGpt] = SimpleRestJsonBuilder(API.service[ChatGpt])
      .client[IO](client)
      .uri(baseUrl)
      .resource
      .map(_.unliftService)

  end ChatGpt

  extension (aic: AiChoice)
    def toMessage: List[AiMessage] =
      List(
        AiMessage.assistant(
          content = aic.message.content,
          tool_calls = aic.message.tool_calls.getOrElse(List.empty)
        )
      )

  case class ChatCompletionFunctions(
      name: String,
      parameters: Document,
      description: Option[String] = None
  ) derives Schema

  enum AiResponseFormat derives Schema:
    case json_object
    case text


end Agent
